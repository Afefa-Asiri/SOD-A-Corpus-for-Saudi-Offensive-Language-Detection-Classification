{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b3784535875b4545adb10d2fcc93421a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a40666e443ea49e7a5532444b22ce663",
              "IPY_MODEL_b9693cb04873486aa58e13f2d436d23e",
              "IPY_MODEL_e874dc8b22124cf3b4b545811dcbae89"
            ],
            "layout": "IPY_MODEL_a1698226899043309d8b7574d32bf597"
          }
        },
        "a40666e443ea49e7a5532444b22ce663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3f7e6ea1f774e7bb2c93e8fca98e759",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_57950220d926454cb7199723d9deea8c",
            "value": "config.json: 100%"
          }
        },
        "b9693cb04873486aa58e13f2d436d23e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7ba1f9d14b94ede97cf888e572e12b6",
            "max": 667,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49bcbfcd249043539400e05ddbea60b0",
            "value": 667
          }
        },
        "e874dc8b22124cf3b4b545811dcbae89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e031afac206d408ab4815c54923a2d22",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c824666b0363448390030afc1dd83ff0",
            "value": " 667/667 [00:00&lt;00:00, 26.8kB/s]"
          }
        },
        "a1698226899043309d8b7574d32bf597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f7e6ea1f774e7bb2c93e8fca98e759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57950220d926454cb7199723d9deea8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7ba1f9d14b94ede97cf888e572e12b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49bcbfcd249043539400e05ddbea60b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e031afac206d408ab4815c54923a2d22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c824666b0363448390030afc1dd83ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bb2054bebaf4b2c9877830af5f88de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_282f942642124ec6b663f747521163d9",
              "IPY_MODEL_f90f39968fb3476681d0755ce77ce4da",
              "IPY_MODEL_4a57322c41e64d83804fff114b014a7c"
            ],
            "layout": "IPY_MODEL_3bdcd9b808dd48dcadec89c8bbea2e50"
          }
        },
        "282f942642124ec6b663f747521163d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a5d0a9b89c049f094ebdfe96b69381f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c447e9a8bf7e442ca54d2c385f49b929",
            "value": "model.safetensors: 100%"
          }
        },
        "f90f39968fb3476681d0755ce77ce4da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5a597707f28488f8cd3b9df5432ed55",
            "max": 541063424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e40b6e1278884feda2e6b34477d4e606",
            "value": 541063424
          }
        },
        "4a57322c41e64d83804fff114b014a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7a6a14992364b05adb14099594acb0f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_289ff4800b174a0abcc429e1420f2634",
            "value": " 541M/541M [00:12&lt;00:00, 35.6MB/s]"
          }
        },
        "3bdcd9b808dd48dcadec89c8bbea2e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a5d0a9b89c049f094ebdfe96b69381f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c447e9a8bf7e442ca54d2c385f49b929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5a597707f28488f8cd3b9df5432ed55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e40b6e1278884feda2e6b34477d4e606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7a6a14992364b05adb14099594acb0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "289ff4800b174a0abcc429e1420f2634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_W4MeROEKNK",
        "outputId": "c5bd090f-e26d-4bb1-f4cd-90204264a642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Sun Dec 10 16:17:26 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    !nvidia-smi\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rcGKrRpOEVgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install farasapy==0.0.14\n",
        "!pip install pyarabic==0.6.14\n",
        "!git clone https://github.com/aub-mind/arabert\n",
        "!pip install emoji==1.6.1\n",
        "!pip install sentencepiece==0.1.96"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-SxvsEAEWBS",
        "outputId": "8b2e03d2-40c6-445a-9be9-c01ea1ca8e9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: farasapy==0.0.14 in /usr/local/lib/python3.10/dist-packages (0.0.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy==0.0.14) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy==0.0.14) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy==0.0.14) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy==0.0.14) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy==0.0.14) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy==0.0.14) (2023.11.17)\n",
            "Requirement already satisfied: pyarabic==0.6.14 in /usr/local/lib/python3.10/dist-packages (0.6.14)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from pyarabic==0.6.14) (1.16.0)\n",
            "fatal: destination path 'arabert' already exists and is not an empty directory.\n",
            "Requirement already satisfied: emoji==1.6.1 in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Requirement already satisfied: sentencepiece==0.1.96 in /usr/local/lib/python3.10/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Creating training datasets"
      ],
      "metadata": {
        "id": "kjLRX9x7GC0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "i7a1myyoFiNj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This custom dataset class will help us hold our datasets in a structred manner"
      ],
      "metadata": {
        "id": "AT4xRQhuGUE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset:\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        train: List[pd.DataFrame],\n",
        "        test: List[pd.DataFrame],\n",
        "        label_list: List[str],\n",
        "    ):\n",
        "        \"\"\"Class to hold and structure datasets.\n",
        "\n",
        "        Args:\n",
        "\n",
        "        name (str): holds the name of the dataset so we can select it later\n",
        "        train (List[pd.DataFrame]): holds training pandas dataframe with 2 columns [\"text\",\"label\"]\n",
        "        test (List[pd.DataFrame]): holds testing pandas dataframe with 2 columns [\"text\",\"label\"]\n",
        "        label_list (List[str]): holds the list  of labels\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.train = train\n",
        "        self.test = test\n",
        "        self.label_list = label_list"
      ],
      "metadata": {
        "id": "HUqE2XU_GUd4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will hold all the downloaded and structred datasets\n",
        "all_datasets= []\n",
        "DATA_COLUMN = \"text\"\n",
        "LABEL_COLUMN = \"label\""
      ],
      "metadata": {
        "id": "hWtq4ODSGjSm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### My Datasets"
      ],
      "metadata": {
        "id": "-o7ETO2DG6oK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. balanced_dataset_synonom"
      ],
      "metadata": {
        "id": "ae4G_EU4G4ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Offensive = pd.read_csv(\"/content/balanced_dataset_synonom_colab.csv\", header=0)\n",
        "ID=0\n",
        "df_Offensive.columns = [ID, DATA_COLUMN, LABEL_COLUMN]\n",
        "\n",
        "train_Offensive, test_Offensive = train_test_split(df_Offensive, test_size=0.2, random_state=42)\n",
        "\n",
        "label_list_Offensive = list(df_Offensive[LABEL_COLUMN].unique())\n",
        "print(label_list_Offensive)\n",
        "print(df_Offensive[LABEL_COLUMN].value_counts())\n",
        "data_Offensive_synonom = CustomDataset( \"synonom_dataset\", train_Offensive, test_Offensive, label_list_Offensive)\n",
        "all_datasets.append(data_Offensive_synonom)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84HsSnynGusY",
        "outputId": "d026c645-a93f-43a5-b49d-5a4cbb9152e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'B']\n",
            "A    17509\n",
            "B    17509\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Balanced_AandBClasses_Oversampled_Revised"
      ],
      "metadata": {
        "id": "fF8vatG7ddrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_Offensive = pd.read_csv(\"/content/Balanced_AandBClasses_Oversampled_Revised.csv\", header=0)\n",
        "ID=0\n",
        "df_Offensive.columns = [ID, DATA_COLUMN, LABEL_COLUMN]\n",
        "\n",
        "train_Offensive, test_Offensive = train_test_split(df_Offensive, test_size=0.2, random_state=42)\n",
        "\n",
        "label_list_Offensive = list(df_Offensive[LABEL_COLUMN].unique())\n",
        "print(label_list_Offensive)\n",
        "print(df_Offensive[LABEL_COLUMN].value_counts())\n",
        "data_Offensive_Oversampled = CustomDataset( \"Oversampled_dataset\", train_Offensive, test_Offensive, label_list_Offensive)\n",
        "all_datasets.append(data_Offensive_Oversampled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bmi1ckvdhtI",
        "outputId": "8da6d2a1-4b97-408a-9680-f92effc878d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['B', 'A']\n",
            "B    7008\n",
            "A    7008\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. SDOffensive_Agu_Shuffled:\n",
        "Trying Augmented Data Using Shuffling."
      ],
      "metadata": {
        "id": "jK-UwhKMTsXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Offensive = pd.read_csv(\n",
        "    \"/content/SDOffensive_Aug_Shuffled.csv\", header=0\n",
        ")\n",
        "ID=0\n",
        "df_Offensive.columns = [ID, DATA_COLUMN, LABEL_COLUMN]\n",
        "\n",
        "train_Offensive, test_Offensive = train_test_split(\n",
        "    df_Offensive, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "label_list_Offensive = list(df_Offensive[LABEL_COLUMN].unique())\n",
        "print(label_list_Offensive)\n",
        "print(df_Offensive[LABEL_COLUMN].value_counts())\n",
        "\n",
        "data_Offensive_Shuffled = CustomDataset(\n",
        "    \"Offensive-Shuffled\", train_Offensive, test_Offensive, label_list_Offensive\n",
        ")\n",
        "\n",
        "all_datasets.append(data_Offensive_Shuffled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkK8jaeEUKD-",
        "outputId": "a43701ba-d0a5-48d4-9366-6342e0dd5bcc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Non-Offensive', 'Offensive']\n",
            "Non-Offensive    17509\n",
            "Offensive        14016\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. SDOffensive_Augmented_GPT2: Trying Augmented data Using GPT-2"
      ],
      "metadata": {
        "id": "SVBeOu7z_tcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Offensive = pd.read_csv(\n",
        "    \"/content/SDOffensive_Augmented_GPT2.csv\", header=0\n",
        ")\n",
        "ID=0\n",
        "df_Offensive.columns = [ID, DATA_COLUMN, LABEL_COLUMN]\n",
        "\n",
        "train_Offensive, test_Offensive = train_test_split(\n",
        "    df_Offensive, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "label_list_Offensive = list(df_Offensive[LABEL_COLUMN].unique())\n",
        "print(label_list_Offensive)\n",
        "print(df_Offensive[LABEL_COLUMN].value_counts())\n",
        "\n",
        "data_Offensive_Augmented_GPT2 = CustomDataset(\n",
        "    \"Offensive-GPT-2\", train_Offensive, test_Offensive, label_list_Offensive\n",
        ")\n",
        "\n",
        "all_datasets.append(data_Offensive_Augmented_GPT2)"
      ],
      "metadata": {
        "id": "zHQ0pWe5AIKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f97933-f41f-4b24-a023-c5d293d3695e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Non-Offensive', 'Offensive']\n",
            "Non-Offensive    17509\n",
            "Offensive        14016\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###List all the datasets we have"
      ],
      "metadata": {
        "id": "xMigmx4_Mksy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x in all_datasets:\n",
        "  print(x.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HER6_76MmOW",
        "outputId": "abaab929-5926-4f18-d0e6-c24665c92be5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "synonom_dataset\n",
            "Oversampled_dataset\n",
            "Offensive-Shuffled\n",
            "Offensive-GPT-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trainer\n",
        "Start the training procedure\n"
      ],
      "metadata": {
        "id": "qNslKmb9N5Af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "from sklearn.metrics import (accuracy_score, classification_report,\n",
        "                             confusion_matrix, f1_score, precision_score,\n",
        "                             recall_score)\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (AutoConfig, AutoModelForSequenceClassification,\n",
        "                          AutoTokenizer, BertTokenizer, Trainer,\n",
        "                          TrainingArguments)\n",
        "from transformers.data.processors.utils import InputFeatures"
      ],
      "metadata": {
        "id": "8AZysVb_N64T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select a dataset\n",
        "dataset_name = 'synonom_dataset'\n",
        "# select a model from the huggingface modelhub https://huggingface.co/models?language=ar\n",
        "model_name = 'aubmindlab/bert-base-arabertv02-twitter' # we are going to use the twitter AraBERT since it has emojis and dialects"
      ],
      "metadata": {
        "id": "7yPbTtYtOOLX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for d in all_datasets:\n",
        "  if d.name==dataset_name:\n",
        "    selected_dataset = copy.deepcopy(d)\n",
        "    print('Dataset found')\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMTwIQ4rOdLv",
        "outputId": "8bbbb726-cd70-448b-f624-9868b5cc6011"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create and apply preprocessing using the AraBERT processor"
      ],
      "metadata": {
        "id": "rEK0-CqoOncK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arabic_prep = ArabertPreprocessor(model_name)\n",
        "\n",
        "selected_dataset.train[DATA_COLUMN] = selected_dataset.train[DATA_COLUMN].apply(lambda x: arabic_prep.preprocess(x))\n",
        "selected_dataset.test[DATA_COLUMN] = selected_dataset.test[DATA_COLUMN].apply(lambda x: arabic_prep.preprocess(x))"
      ],
      "metadata": {
        "id": "rux2EJk5OtE_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check on the dataset\n",
        "list(selected_dataset.train[DATA_COLUMN][0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c60xKB2BOy_o",
        "outputId": "e9836cee-02bd-49c8-a4eb-a19d39c276d7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['USER USER ÿπŸÜÿØŸáŸÖ ÿßŸÑŸÇÿßÿ® ÿ®ŸàŸÑŸÜÿØÿß ŸÖ ÿπŸÜÿØŸáÿß',\n",
              " '# ŸÉŸÑŸÜÿß _ ŸÖÿπŸÉ _ ŸäÿßŸÑÿ≥ŸàŸÖŸáNLÿ™ÿπÿßŸÑ # ÿßŸÑÿßÿ™ÿ≠ÿßÿØ Ÿàÿßÿ™ÿ±ŸÉ # ÿßŸÑÿ£ŸáŸÑŸä ÿ™ÿ±ÿß ŸÖÿßŸÖÿπÿßŸáŸÖ ÿßŸÑÿß 3 ÿØŸàÿ±ŸäNL0 ÿ¢ÿ≥ŸäÿßNLŸàŸÑÿß ÿ®ÿ∑ŸàŸÑÿ© ÿÆÿßÿ±ÿ¨Ÿäÿ© ÿ™ÿ∞ŸÉÿ±NLÿπÿØŸÜÿßŸÜ ŸÅŸÑÿßÿ™Ÿá ÿ®ÿ™ÿßÿ±ŸäÿÆ ÿßŸÑÿ£ŸáŸÑŸä üòÇ NLÿßŸÑŸÑÿßÿπÿ® Ÿàÿ¥ ŸäŸáŸÖÿ© ÿ∫Ÿäÿ± ÿßŸÑÿ•ŸÜÿ¨ÿßÿ≤ÿßÿ™NLÿ™ÿπÿßŸÑ Ÿäÿßÿ±ÿ¨ÿßŸÑ ÿπŸÜÿØ ÿ¨ŸÖŸáŸàÿ± ÿßŸÑÿ•ÿ™ÿ≠ÿßÿØ ÿßŸÑÿπÿ∏ŸäŸÖNLUSER URL',\n",
              " 'ŸÑÿßŸÅÿßÿ≤ # ÿßŸÑÿßŸáŸÑŸä ÿ™ŸÜÿßŸÖ ÿßŸÑÿ£ÿ±ÿ∂ ŸÖÿ®ÿ≥Ÿàÿ∑ŸáNLÿßŸÑÿπÿ¥ÿ® ÿ≥ÿ± ÿ•ÿ®ÿ™ÿ≥ÿßŸÖÿ™Ÿáÿß ŸàŸÅÿ±ÿ≠ÿ™ŸáÿßNLNLÿßŸÑŸÑŸá Ÿäÿ±ÿ≠ŸÖŸÉ ŸäÿßŸÖÿ≥ÿßÿπÿØ ÿßŸÑÿ±ÿ¥ŸäÿØŸä URL',\n",
              " 'ŸàŸÇÿ™ ÿßŸÑÿßÿÆÿ™ÿ®ÿßÿ± ÿ®ŸäÿÆŸÑÿµ ŸàÿßŸÑÿØŸÉÿ™Ÿàÿ±Ÿá ŸÖÿßÿ¥ÿ±ŸÅÿ™ üò°',\n",
              " 'USER Ÿäÿ±ÿ≠ŸÖ ÿßŸÖŸÉ ÿ™ŸÉŸÅŸâ ÿ±ÿ≠ ŸÑ ÿßÿØÿßÿ±Ÿá ÿßŸÑŸÜÿßÿØŸä ŸÇŸÑŸáŸÖ ÿßŸÜÿß ÿ≠ŸÖÿßÿ± ŸÖ ÿßÿπÿ±ŸÅ ÿßŸÑÿπÿ® ŸàÿßŸÑŸÑŸá ŸÖÿßÿ®Ÿáÿß ÿ¥Ÿä ÿßŸÑŸÑŸá ŸäÿßÿÆÿ∞ŸÉ',\n",
              " 'USER ÿßŸÜÿ™ÿ®Ÿá ŸÖŸÜ ÿßŸÑŸÜÿ≥ŸàÿßŸÜ ŸáŸá ŸÉŸÑ ŸÖÿßŸÉÿ´ÿ±Ÿàÿß ÿ≤ÿßÿØÿ™ ÿßŸÑŸáŸÖŸàŸÖ üòÇ üòÇ üíî ÿßŸÑŸÑŸá ŸäŸàŸÅŸÇŸÉ üíú ü§≤ üèª',\n",
              " 'ŸÖÿßÿØŸäÿ≥ŸàŸÜ ŸÖŸÉÿßŸÜ ŸáŸÜÿØÿ±ÿ≥ŸàŸÜ Ÿä ÿÆŸÜÿ≤Ÿäÿ±',\n",
              " 'ŸÑŸÑÿßÿ≥ŸÅ ŸÜÿßÿ≥ ŸÇÿßÿπÿØ ÿ™ÿØŸàÿ± ÿßŸÑÿ¥Ÿáÿ±ÿ© ÿπŸÑŸâ ÿ≠ÿ≥ÿßÿ® ÿ∫Ÿäÿ±Ÿáÿß ! ! üí© üí©',\n",
              " 'ŸäÿßŸÑŸäŸäŸÑ ÿßŸÑŸÉÿ∞ÿßÿ®Ÿá ÿßŸÑÿ´ÿßŸÜŸäŸäŸá ŸÖÿ≥ÿßŸÅŸÅÿ±Ÿá Ÿàÿ™ŸÉÿ™ÿ® ÿπŸÜ ÿßŸÑŸàÿ∑ÿ∑ŸÜ üëø üëø',\n",
              " 'USER USER ÿßÿ∞ÿß Ÿáÿ∞ÿß 70 ÿßŸÑŸÅ ÿ®ÿßŸÑÿ≥ÿßÿπÿ© ÿßÿ¨ŸÑ ÿßŸÑŸÅŸÜÿßŸÜŸäŸäŸÜ ÿßŸÑÿ´ÿßŸÜŸäŸäŸÜ ÿßŸÑŸÑŸä ÿßŸÇÿØŸÖ ŸÖŸÜŸá Ÿàÿ£ÿ¥Ÿáÿ± ŸÖŸÜŸá ŸÉŸÖ Ÿäÿ≥ÿ™ŸÑŸÖŸàŸÜ ÿ®ÿßŸÑÿ≥ÿßÿπÿ© ŸÖŸÑŸäŸàŸÜ ÿ±ŸäÿßŸÑ ü§¨ üò† üò° ü•µ']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-\n",
        "Now we need to check the tokenized sentence length to decide on the maximum sentence length value"
      ],
      "metadata": {
        "id": "JCzpuGyHO6UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tok = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "yi9gpF_LO7q8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Sentence Lengths: \")\n",
        "plt.hist([ len(tok.tokenize(sentence)) for sentence in selected_dataset.train[DATA_COLUMN].to_list()],bins=range(0,128,2))\n",
        "plt.show()\n",
        "\n",
        "print(\"Testing Sentence Lengths: \")\n",
        "plt.hist([ len(tok.tokenize(sentence)) for sentence in selected_dataset.test[DATA_COLUMN].to_list()],bins=range(0,128,2))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "id": "IJkCDCwVO_ND",
        "outputId": "789de3b5-8db2-4671-97df-80ade4fe4b01"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Sentence Lengths: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Sentence Lengths: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Let's select 100 as our maximum sentence length, and check how many sequences will be truncated"
      ],
      "metadata": {
        "id": "5MbEHAeMPUnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 128"
      ],
      "metadata": {
        "id": "hSzVsMVwPVyA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Truncated training sequences: \", sum([len(tok.tokenize(sentence)) > max_len for sentence in selected_dataset.test[DATA_COLUMN].to_list()]))\n",
        "\n",
        "print(\"Truncated testing sequences: \", sum([len(tok.tokenize(sentence)) > max_len for sentence in selected_dataset.test[DATA_COLUMN].to_list()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0KguNPHPZVU",
        "outputId": "40024195-aa41-4203-a933-48a1a4c36181"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Truncated training sequences:  1\n",
            "Truncated testing sequences:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good // I will explain here what is this process using GPT-4 support. as we will miss 0 data! so, no data will be deleted"
      ],
      "metadata": {
        "id": "1PlEZ5yvPj7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now let's create a classification dataset to load the data"
      ],
      "metadata": {
        "id": "Pah_8d_-P2Lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationDataset(Dataset):\n",
        "    def __init__(self, text, target, model_name, max_len, label_map):\n",
        "      super(ClassificationDataset).__init__()\n",
        "      \"\"\"\n",
        "      Args:\n",
        "      text (List[str]): List of the training text\n",
        "      target (List[str]): List of the training labels\n",
        "      tokenizer_name (str): The tokenizer name (same as model_name).\n",
        "      max_len (int): Maximum sentence length\n",
        "      label_map (Dict[str,int]): A dictionary that maps the class labels to integer\n",
        "      \"\"\"\n",
        "      self.text = text\n",
        "      self.target = target\n",
        "      self.tokenizer_name = model_name\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "      self.max_len = max_len\n",
        "      self.label_map = label_map\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.text)\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "      text = str(self.text[item])\n",
        "      text = \" \".join(text.split())\n",
        "\n",
        "      inputs = self.tokenizer(\n",
        "          text,\n",
        "          max_length=self.max_len,\n",
        "          padding='max_length',\n",
        "          truncation=True\n",
        "      )\n",
        "      return InputFeatures(**inputs,label=self.label_map[self.target[item]])"
      ],
      "metadata": {
        "id": "FRuvTffNP4mX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = { v:index for index, v in enumerate(selected_dataset.label_list) }\n",
        "print(label_map)\n",
        "\n",
        "train_dataset = ClassificationDataset(\n",
        "    selected_dataset.train[DATA_COLUMN].to_list(),\n",
        "    selected_dataset.train[LABEL_COLUMN].to_list(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )\n",
        "test_dataset = ClassificationDataset(\n",
        "    selected_dataset.test[DATA_COLUMN].to_list(),\n",
        "    selected_dataset.test[LABEL_COLUMN].to_list(),\n",
        "    model_name,\n",
        "    max_len,\n",
        "    label_map\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dweRmjJP_nG",
        "outputId": "2ec828c4-7912-4e07-d053-a2d1909da056"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'A': 0, 'B': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Check the dataset output"
      ],
      "metadata": {
        "id": "y4uM9LwuQKt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(iter(train_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "homVkTQZQMeC",
        "outputId": "2d23ceb3-535a-46b3-9ca9-4ca1b7bc1003"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "InputFeatures(input_ids=[2, 46160, 33573, 46160, 33573, 19345, 7008, 14783, 136, 10543, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a function that return a pretrained model ready to do classification\n"
      ],
      "metadata": {
        "id": "MFfD846vQc2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_init():\n",
        "    return AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=len(label_map))"
      ],
      "metadata": {
        "id": "y0l9BEa_Qeth"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define whatever metric you want here:"
      ],
      "metadata": {
        "id": "IMuST1r3Qk2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def compute_metrics(p): #p should be of type EvalPrediction\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  assert len(preds) == len(p.label_ids)\n",
        "  #print(classification_report(p.label_ids,preds))\n",
        "  #print(confusion_matrix(p.label_ids,preds))\n",
        "  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
        "  #macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
        "  #macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
        "  acc = accuracy_score(p.label_ids,preds)\n",
        "  return {\n",
        "      'macro_f1' : macro_f1,\n",
        "      'accuracy': acc\n",
        "  }\n",
        "  '''"
      ],
      "metadata": {
        "id": "K1vHNJN5QmUw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9959bf2b-4b06-40ac-9186-2a52fd954148"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef compute_metrics(p): #p should be of type EvalPrediction\\n  preds = np.argmax(p.predictions, axis=1)\\n  assert len(preds) == len(p.label_ids)\\n  #print(classification_report(p.label_ids,preds))\\n  #print(confusion_matrix(p.label_ids,preds))\\n  macro_f1 = f1_score(p.label_ids,preds,average='macro')\\n  #macro_precision = precision_score(p.label_ids,preds,average='macro')\\n  #macro_recall = recall_score(p.label_ids,preds,average='macro')\\n  acc = accuracy_score(p.label_ids,preds)\\n  return {\\n      'macro_f1' : macro_f1,\\n      'accuracy': acc\\n  }\\n  \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#----- From My Thoughts @_@\n",
        "\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    assert len(preds) == len(p.label_ids)\n",
        "\n",
        "    macro_F1 = f1_score(p.label_ids, preds, average='macro')\n",
        "    micro_F1 = f1_score(p.label_ids, preds, average='micro')\n",
        "    weighted_F1 = f1_score(p.label_ids, preds, average='weighted')\n",
        "\n",
        "    macro_precision = precision_score(p.label_ids, preds, average='macro')\n",
        "    macro_recall = recall_score(p.label_ids, preds, average='macro')\n",
        "\n",
        "    micro_precision = precision_score(p.label_ids, preds, average='micro')\n",
        "    micro_recall = recall_score(p.label_ids, preds, average='micro')\n",
        "\n",
        "    weighted_precision = precision_score(p.label_ids, preds, average='weighted')\n",
        "    weighted_recall = recall_score(p.label_ids, preds, average='weighted')\n",
        "\n",
        "    acc = accuracy_score(p.label_ids, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'Precision_macro': macro_precision,\n",
        "        'Recall_macro': macro_recall,\n",
        "        'macro_f1': macro_F1,\n",
        "\n",
        "        'Precision_micro': micro_precision,\n",
        "        'Recall_micro': micro_recall,\n",
        "        'F1_micro': micro_F1,\n",
        "\n",
        "        'Precision_weighted': weighted_precision,\n",
        "        'Recall_weighted': weighted_recall,\n",
        "        'F1_weighted': weighted_F1\n",
        "    }"
      ],
      "metadata": {
        "id": "90XPl0IVdXcC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lets Do the follwing Classification Report to match my work on other classfiers:"
      ],
      "metadata": {
        "id": "a2vPCo7QEDTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def compute_metrics(p): #p should be of type EvalPrediction\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    assert len(preds) == len(p.label_ids)\n",
        "\n",
        "    # Get unique labels from both true and predicted labels\n",
        "    unique_labels = np.unique(np.concatenate((p.label_ids, preds)))\n",
        "\n",
        "    report = classification_report(p.label_ids, preds, labels=unique_labels, output_dict=True)\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(p.label_ids, preds),\n",
        "        'precision_non_offensive': report['Non-Offensive']['precision'],\n",
        "        'recall_non_offensive': report['Non-Offensive']['recall'],\n",
        "        'f1_non_offensive': report['Non-Offensive']['f1-score'],\n",
        "        'precision_offensive': report['Offensive']['precision'],\n",
        "        'recall_offensive': report['Offensive']['recall'],\n",
        "        'f1_offensive': report['Offensive']['f1-score'],\n",
        "        'macro_avg_precision': report['macro avg']['precision'],\n",
        "        'macro_avg_recall': report['macro avg']['recall'],\n",
        "        'macro_avg_f1': report['macro avg']['f1-score'],\n",
        "        'weighted_avg_precision': report['weighted avg']['precision'],\n",
        "        'weighted_avg_recall': report['weighted avg']['recall'],\n",
        "        'weighted_avg_f1': report['weighted avg']['f1-score'],\n",
        "    }\n",
        "    return metrics\n",
        "'''"
      ],
      "metadata": {
        "id": "cBb6fv7iEJZc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "d07b71ff-71f3-4321-daca-d4891569bfc1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom sklearn.metrics import classification_report\\n\\ndef compute_metrics(p): #p should be of type EvalPrediction\\n    preds = np.argmax(p.predictions, axis=1)\\n    assert len(preds) == len(p.label_ids)\\n\\n    # Get unique labels from both true and predicted labels\\n    unique_labels = np.unique(np.concatenate((p.label_ids, preds)))\\n\\n    report = classification_report(p.label_ids, preds, labels=unique_labels, output_dict=True)\\n\\n    metrics = {\\n        'accuracy': accuracy_score(p.label_ids, preds),\\n        'precision_non_offensive': report['Non-Offensive']['precision'],\\n        'recall_non_offensive': report['Non-Offensive']['recall'],\\n        'f1_non_offensive': report['Non-Offensive']['f1-score'],\\n        'precision_offensive': report['Offensive']['precision'],\\n        'recall_offensive': report['Offensive']['recall'],\\n        'f1_offensive': report['Offensive']['f1-score'],\\n        'macro_avg_precision': report['macro avg']['precision'],\\n        'macro_avg_recall': report['macro avg']['recall'],\\n        'macro_avg_f1': report['macro avg']['f1-score'],\\n        'weighted_avg_precision': report['weighted avg']['precision'],\\n        'weighted_avg_recall': report['weighted avg']['recall'],\\n        'weighted_avg_f1': report['weighted avg']['f1-score'],\\n    }\\n    return metrics\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  torch.backends.cudnn.deterministic=True\n",
        "  torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "BOnviCKIQ7mP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-fold Training:"
      ],
      "metadata": {
        "id": "AGDxzOxlRGBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is bit more advanced.\n",
        "\n",
        "We will divide the training set into K-folds and train model with cross-validation to check for the best hyper-parameters before check the performance on the test set.\n",
        "\n",
        "Alternatively, you can combine the training and testing set if you are participating in a competition, then ensemble the output models"
      ],
      "metadata": {
        "id": "LNYk2y9OROgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do kfold on the training. Check the perfomance on the test set\n",
        "kfold_dataset = selected_dataset.train\n",
        "# do kfold on all the dataset. Here we will not have any dataset to checl final performance on (this is used mainly in competitions)\n",
        "# kfold_dataset = pd.concat([selected_dataset.train,selected_dataset.test])\n",
        "kfold_dataset.reset_index(inplace=True,drop=True)"
      ],
      "metadata": {
        "id": "NNd9m271RJrv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is used later\n",
        "inv_label_map = { v:k for k, v in label_map.items()}"
      ],
      "metadata": {
        "id": "5tSY8XD2RS5A"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Defing the number of Stratified kfold splits"
      ],
      "metadata": {
        "id": "sHg_XN-pRX4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "kf = StratifiedKFold(\n",
        "    n_splits=5,\n",
        "    shuffle=True,\n",
        "    random_state=123\n",
        "  )"
      ],
      "metadata": {
        "id": "h8nRFXURRYkW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train using cross validation and save the best model at each fold"
      ],
      "metadata": {
        "id": "-L9LFWO6RdhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install transformers\n",
        "!pip install accelerate -U\n",
        "!pip install accelerate>=0.20.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl_Bfr97U8HB",
        "outputId": "da228fcc-01f2-4a58-ad48-e0b17f8ac5d8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] accelerate -U\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTy-uzlUVRnb",
        "outputId": "c5a9db14-d543-4e42-9c73-13fe9445e1d1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip show transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tamz0OpCU_SR",
        "outputId": "16e83b76-6cfb-406c-d129-acaae70c3e29"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.35.2\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip show accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS1RHzUqVNgU",
        "outputId": "492ba191-12f5-4964-eb75-be8ecf39912f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: accelerate\n",
            "Version: 0.25.0\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: sylvain@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nMnr2QeV_7N",
        "outputId": "cb95db1f-3e11-46b1-d7e3-43267d0002c5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip show torch torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh--m_SYWFBm",
        "outputId": "9a82ac84-4895-475c-e38c-e4c3c3fe17da"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.1.0+cu118\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, sympy, triton, typing-extensions\n",
            "Required-by: accelerate, fastai, torchaudio, torchdata, torchtext, torchvision\n",
            "---\n",
            "Name: torchvision\n",
            "Version: 0.16.0+cu118\n",
            "Summary: image and video datasets and models for torch deep learning\n",
            "Home-page: https://github.com/pytorch/vision\n",
            "Author: PyTorch Core Team\n",
            "Author-email: soumith@pytorch.org\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, pillow, requests, torch\n",
            "Required-by: fastai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "kpylneHxWOar"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ6LOf7vWlzs",
        "outputId": "234b9fe0-9322-47c9-980b-d1fe5fb0eded"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_results = []\n",
        "fold_best_f1 = 0\n",
        "best_fold = None\n",
        "\n",
        "for fold_num , (train, dev) in enumerate(kf.split(kfold_dataset,kfold_dataset['label'])):\n",
        "  print(\"**************************Starting Fold Num: \", fold_num,\" **************************\")\n",
        "\n",
        "  train_dataset = ClassificationDataset(list(kfold_dataset[DATA_COLUMN][train]),\n",
        "                              list(kfold_dataset[LABEL_COLUMN][train]),\n",
        "                              model_name,\n",
        "                              max_len,\n",
        "                              label_map)\n",
        "\n",
        "  val_dataset = ClassificationDataset(list(kfold_dataset[DATA_COLUMN][dev]),\n",
        "                              list(kfold_dataset[LABEL_COLUMN][dev]),\n",
        "                              model_name,\n",
        "                              max_len,\n",
        "                              label_map)\n",
        "\n",
        "  training_args = TrainingArguments(\n",
        "    output_dir= f\"./train_{fold_num}\",\n",
        "    adam_epsilon = 1e-8,\n",
        "    learning_rate = 2e-5,\n",
        "    fp16 = False,\n",
        "    per_device_train_batch_size = 64,\n",
        "    per_device_eval_batch_size = 128,\n",
        "    gradient_accumulation_steps = 2,\n",
        "    num_train_epochs= 2,\n",
        "    warmup_ratio = 0,\n",
        "    do_eval = True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy = 'epoch',\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = 'macro_f1',\n",
        "    greater_is_better = True,\n",
        "    seed = 123\n",
        "  )\n",
        "\n",
        "  set_seed(training_args.seed)\n",
        "\n",
        "  trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "  )\n",
        "  trainer.model.config.label2id = label_map\n",
        "  trainer.model.config.id2label = inv_label_map\n",
        "\n",
        "  trainer.train()\n",
        "\n",
        "  results = trainer.evaluate()\n",
        "  all_results.append(results)\n",
        "  print(results)\n",
        "\n",
        "  trainer.save_model(f\"./train_{fold_num}/best_model\")\n",
        "  val_dataset.tokenizer.save_pretrained(f\"./train_{fold_num}/best_model\")\n",
        "\n",
        "  # delete the rest of the checkpoints\n",
        "  !rm -rf f\"./train_{fold_num}/checkpoint-*\"\n",
        "\n",
        "  if results['eval_macro_f1'] > fold_best_f1:\n",
        "    print('**************************New Best Model Found!**************************')\n",
        "    fold_best_f1 = results['eval_macro_f1']\n",
        "    best_fold = fold_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "b3784535875b4545adb10d2fcc93421a",
            "a40666e443ea49e7a5532444b22ce663",
            "b9693cb04873486aa58e13f2d436d23e",
            "e874dc8b22124cf3b4b545811dcbae89",
            "a1698226899043309d8b7574d32bf597",
            "a3f7e6ea1f774e7bb2c93e8fca98e759",
            "57950220d926454cb7199723d9deea8c",
            "c7ba1f9d14b94ede97cf888e572e12b6",
            "49bcbfcd249043539400e05ddbea60b0",
            "e031afac206d408ab4815c54923a2d22",
            "c824666b0363448390030afc1dd83ff0",
            "1bb2054bebaf4b2c9877830af5f88de6",
            "282f942642124ec6b663f747521163d9",
            "f90f39968fb3476681d0755ce77ce4da",
            "4a57322c41e64d83804fff114b014a7c",
            "3bdcd9b808dd48dcadec89c8bbea2e50",
            "8a5d0a9b89c049f094ebdfe96b69381f",
            "c447e9a8bf7e442ca54d2c385f49b929",
            "f5a597707f28488f8cd3b9df5432ed55",
            "e40b6e1278884feda2e6b34477d4e606",
            "c7a6a14992364b05adb14099594acb0f",
            "289ff4800b174a0abcc429e1420f2634"
          ]
        },
        "id": "XXwPIJicReSx",
        "outputId": "e572686f-b5cb-4aa8-b8b4-958fd2094f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************Starting Fold Num:  0  **************************\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/667 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3784535875b4545adb10d2fcc93421a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/541M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bb2054bebaf4b2c9877830af5f88de6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.weight', 'classifier.bias', 'bert.pooler.dense.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='241' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [241/350 10:11 < 04:39, 0.39 it/s, Epoch 1.37/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision Macro</th>\n",
              "      <th>Recall Macro</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Precision Micro</th>\n",
              "      <th>Recall Micro</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.270762</td>\n",
              "      <td>0.881492</td>\n",
              "      <td>0.881558</td>\n",
              "      <td>0.881486</td>\n",
              "      <td>0.881486</td>\n",
              "      <td>0.881492</td>\n",
              "      <td>0.881492</td>\n",
              "      <td>0.881492</td>\n",
              "      <td>0.881554</td>\n",
              "      <td>0.881492</td>\n",
              "      <td>0.881486</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean\n",
        "mean([x['eval_macro_f1'] for x in all_results])"
      ],
      "metadata": {
        "id": "_zB88TnnRspm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble all the cross validation models:"
      ],
      "metadata": {
        "id": "7k6T3bNoR_2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import more_itertools"
      ],
      "metadata": {
        "id": "kOO4iKCFSClt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_label_map = { v:k for k, v in label_map.items()}"
      ],
      "metadata": {
        "id": "4DvMBDAfSE2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_df = prediction['Text']\n",
        "# pred_df = pred_df.apply(lambda x:   arabic_prep.preprocess(x))\n",
        "\n",
        "pred_df = selected_dataset.test[DATA_COLUMN]"
      ],
      "metadata": {
        "id": "Vcy8wZB6SIO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_df = pd.DataFrame([])\n",
        "for i in range(0,5):\n",
        "  pipe = pipeline(\"sentiment-analysis\", model=f\"train_{i}/best_model\", device=0, return_all_scores =True, max_length=max_len, truncation=True)\n",
        "  preds = []\n",
        "  for s in tqdm(more_itertools.chunked(list(pred_df), 32)): # batching for faster inference\n",
        "    preds.extend(pipe(s))\n",
        "  cross_val_df[f'model_{i}'] = preds"
      ],
      "metadata": {
        "id": "hATeznTgSKbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "final_labels = []\n",
        "final_scores = []\n",
        "for id, row in cross_val_df.iterrows():\n",
        "  total_score = defaultdict(lambda: 0)\n",
        "  for pred in row:\n",
        "    for cls in pred:\n",
        "      total_score[cls['label']] += cls['score']\n",
        "\n",
        "  avg_score = { k: v/ 5 for k, v in total_score.items()}\n",
        "\n",
        "  final_labels.append(max(avg_score, key=avg_score.get))\n",
        "  final_scores.append(avg_score[max(avg_score, key=avg_score.get)])"
      ],
      "metadata": {
        "id": "xsgtg4N0SM_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_df['preds'] = final_labels\n",
        "cross_val_df['sentiment_score'] = final_scores"
      ],
      "metadata": {
        "id": "wjAU2Bs0SPTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_df['preds'].value_counts()"
      ],
      "metadata": {
        "id": "hViYjuasSRWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(selected_dataset.test[LABEL_COLUMN],cross_val_df['preds']))"
      ],
      "metadata": {
        "id": "dTHcZwlyST4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get classification report in dictionary format\n",
        "report = classification_report(selected_dataset.test[LABEL_COLUMN], cross_val_df['preds'], output_dict=True)\n",
        "\n",
        "# Extract and print required metrics\n",
        "precision = report['weighted avg']['precision']\n",
        "precision_macro = report['macro avg']['precision']\n",
        "\n",
        "recall = report['weighted avg']['recall']\n",
        "recall_macro = report['macro avg']['recall']\n",
        "\n",
        "f1 = report['weighted avg']['f1-score']\n",
        "f1_macro = report['macro avg']['f1-score']\n",
        "f1_micro = f1_score(selected_dataset.test[LABEL_COLUMN], cross_val_df['preds'], average='micro')\n",
        "\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(selected_dataset.test[LABEL_COLUMN], cross_val_df['preds']))\n",
        "\n",
        "print(f\"\\nPrecision (Weighted): {precision:.2f}\")\n",
        "print(f\"Precision (Macro): {precision_macro:.2f}\")\n",
        "print(f\"Recall (Weighted): {recall:.2f}\")\n",
        "print(f\"Recall (Macro): {recall_macro:.2f}\")\n",
        "print(f\"F1-Score (Weighted): {f1:.2f}\")\n",
        "print(f\"F1-Score (Macro): {f1_macro:.2f}\")\n",
        "print(f\"F1-Score (Micro): {f1_micro:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YVkthc_ROMSG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}